{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import operator\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import fitz\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genus_blocks(page_df, draw, color = '#6c899e', w = 3):\n",
    "    try:\n",
    "        genus_list = page_df['draw_genus'].unique()\n",
    "    except:\n",
    "        #print(\"no GENUS found\")\n",
    "        return \n",
    "\n",
    "    for g in genus_list:\n",
    "        temp_df = page_df[(page_df['draw_genus'] == g)]\n",
    "        g_x0 = temp_df['x0'].min()\n",
    "        g_y0 = temp_df['y0'].min()\n",
    "        g_x1 = temp_df['x1'].max()\n",
    "        g_y1 = temp_df['y1'].max()\n",
    "\n",
    "        draw.rectangle((g_x0, g_y0, g_x1, g_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "        \n",
    "def plot_epithet_blocks(page_df, draw, color = '#660066', w = 3):\n",
    "    try:\n",
    "        epithet_list = page_df['draw_epithet'].unique()\n",
    "    except:\n",
    "        print(\"no EPITHET found\")\n",
    "        return \n",
    "    \n",
    "    for e in epithet_list:\n",
    "        temp_df = page_df[(page_df['draw_epithet'] == e)]\n",
    "        e_x0 = temp_df['x0'].min()\n",
    "        e_y0 = temp_df['y0'].min()\n",
    "        e_x1 = temp_df['x1'].max()\n",
    "        e_y1 = temp_df['y1'].max()\n",
    "\n",
    "        draw.rectangle((e_x0, e_y0, e_x1, e_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_author_blocks(page_df, draw, color = '#a3a3a3', w = 1):\n",
    "    try:\n",
    "        author_list = page_df['draw_author'].unique()\n",
    "    except:\n",
    "        print(\"no AUTHOR found\")\n",
    "        return \n",
    "\n",
    "    for a in author_list:\n",
    "        temp_df = page_df[(page_df['draw_author'] == a)]\n",
    "        e_x0 = temp_df['x0'].min()\n",
    "        e_y0 = temp_df['y0'].min()\n",
    "        e_x1 = temp_df['x1'].max()\n",
    "        e_y1 = temp_df['y1'].max()\n",
    "\n",
    "        draw.rectangle((e_x0, e_y0, e_x1, e_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_infra_blocks(page_df, draw, color = '#ff6289', w = 1):\n",
    "    try:\n",
    "        infra_list = page_df['draw_infra'].unique()\n",
    "    except:\n",
    "        print(\"no INFRA Spp. found\")\n",
    "        return \n",
    "\n",
    "    for infra_spp in infra_list:\n",
    "        temp_df = page_df[(page_df['draw_infra'] == infra_spp)]\n",
    "        e_x0 = temp_df['x0'].min()\n",
    "        e_y0 = temp_df['y0'].min()\n",
    "        e_x1 = temp_df['x1'].max()\n",
    "        e_y1 = temp_df['y1'].max()\n",
    "\n",
    "        draw.rectangle((e_x0, e_y0, e_x1, e_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_valid_words(page_df, draw, color = '#660044', w = 2):\n",
    "    blocks = page_df['block_no'].unique()\n",
    "    \"\"\"for b in blocks:\n",
    "        lines = page_df[page_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            cond = (page_df['line_no'] == l) & (page_df['block_no'] == b)\n",
    "            words = page_df[cond]['word_no'].unique()\n",
    "            page_df = page_df.copy()\n",
    "            for w in words:\n",
    "                x0 = page_df[(cond) & (page_df['word_no'] == w)]['x0'].item()\n",
    "                y0 = page_df[(cond) & (page_df['word_no'] == w)]['y0'].item()\n",
    "                x1 = page_df[(cond) & (page_df['word_no'] == w)]['x1'].item()\n",
    "                y1 = page_df[(cond) & (page_df['word_no'] == w)]['y1'].item()\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "    \"\"\"\n",
    "    for index, row in page_df.iterrows():\n",
    "        x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1'] \n",
    "        draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(color), width = w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Vol1 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf\"\n",
    "pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf\"\n",
    "index = range(616, 639)\n",
    "doc = fitz.open(pdf_dir)\n",
    "pages = [doc[i] for i in range(doc.page_count)] #doesn't work anymore? [doc[i] for i in range(doc.pageCount)]\n",
    "#index = list(range(555, 583))\n",
    "\n",
    "pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf\"\n",
    "index = range(616, 639)\n",
    "\n",
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)\n",
    "\n",
    "indent_groups = []\n",
    "indent_err = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regex based boolean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(word):\n",
    "    \"\"\"\n",
    "    valid words are words that are:\n",
    "    - at least 2 characters\n",
    "        - unless it's x (symbol for hybrid)\n",
    "    \"\"\"\n",
    "    return (not bool(re.search(r\"[0-9]+[,.]?\", word))) and \\\n",
    "            (word != 'NOUVELLE' and word != 'FLORE') and \\\n",
    "            (len(word) > 1 or \\\n",
    "                word == 'x' or word == 'X' or word == '×' or word == r'\\u00D7') and \\\n",
    "            ''.join(e for e in word if e.isalpha()).isalpha()\n",
    "    \n",
    "def is_genus(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be a genus if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - first letter upper case\n",
    "        - all but first lowecase \n",
    "    in regex: ^[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+$ #ignoring strict beggining and end cause of noise\n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ\\u00D7]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "\n",
    "def is_epithet(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be an epithet if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - all letters lowecase \n",
    "    in regex: ^[a-zàâäèéêëîïôœùûüÿç]+[-]?[a-zàâäèéêëîïôœùûüÿç]+$ #ignoring strict beggining and end cause of noise \n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"[a-zàâäèéêëîïôœùûüÿç\\u00D7]+[-]?[a-zàâäèéêëîïôœùûüÿç]+\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "def is_hybrid(word):\n",
    "    regex = r\"^(([Xx\\u00D7])|([Xx\\u00D7]\\.))$\"\n",
    "    return re.search(regex, word)\n",
    "\n",
    "def is_infra(word):\n",
    "    regex = r\"^(var\\.)|(subsp\\.)\"\n",
    "    return re.search(regex, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(page_num, indent_err = 30):\n",
    "    \n",
    "    #initiate dataframe\n",
    "    #using get_text_words to extract 'block_no', 'line_no', 'word_no'\n",
    "    \n",
    "    words_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    words_df['b_l_tuple'] = tuple(zip(words_df['block_no'], words_df['line_no']))\n",
    "    #using get_text to extract 'size', 'flags', 'font'\n",
    "    #NOTE: not sure if this is the best way to go about this ...\n",
    "    content_blocks_df = pd.DataFrame(pages[page_num].get_text(\"dict\")['blocks'])\n",
    "    line_dicts = content_blocks_df[~content_blocks_df['lines'].isnull()].explode('lines', ignore_index=False)\n",
    "\n",
    "    content_df = pd.DataFrame(list((pd.DataFrame(list(line_dicts['lines']))['spans'].explode('spans'))))\n",
    "    content_df = content_df[content_df['text'] != ' ']\n",
    "    content_df['text'] = content_df['text']\n",
    "    content_df['text'] = content_df['text'].apply(lambda x : list(x.split()))\n",
    "    content_df = content_df.explode('text')\n",
    "    split_bbox_df = pd.DataFrame(content_df['bbox'].tolist(), columns=['x0', 'y0', 'x1', 'y1'])\n",
    "    pretty_content_df = pd.concat([content_df.reset_index(), split_bbox_df], axis=1)\n",
    "\n",
    "    #have to take this step beforem merging the words don't match even when they should -- matching based on bbox won't help with this either :( \n",
    "    pretty_content_df = pretty_content_df[pretty_content_df[\"text\"].apply(valid)].reset_index()\n",
    "    words_df = words_df[words_df[\"word\"].apply(valid)].reset_index()\n",
    "\n",
    "    joined_df = pd.concat([pretty_content_df, words_df], axis=1)\n",
    "    #the rows of each row should correspond. This following assertion assures that this is the case\n",
    "    #TODO: might be worthwhile to match according to bbox coordinates (x0, y0, x1, y1) and in_x0, in_y0, in_x1, in_y1\n",
    "    try:\n",
    "        assert joined_df[joined_df['text'] != joined_df['word']].empty\n",
    "    except:\n",
    "        print(\"failed on page\", page_num)\n",
    "\n",
    "    page_df = joined_df[['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'text','block_no', 'line_no', 'word_no', 'flags', 'font', 'size', 'color', 'b_l_tuple']]\n",
    "    \n",
    "    #initiate all columns that will be added\n",
    "    page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    page_df['genus'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_genus'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['epithet'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_epithet'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['author'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_author'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['infra'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_infra'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['taxon rank'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['error_check'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    \n",
    "    #remove italics\n",
    "    #italics_b_l = page_df[page_df['flags'] != 6]['b_l_tuple']\n",
    "    #page_df = page_df[page_df['b_l_tuple'].apply(lambda x : x in italics_b_l.unique())]\n",
    "    #italics_b_l = page_df[page_df['flags'] != 6]['b_l_tuple'].unique()\n",
    "    #page_df = page_df[page_df['b_l_tuple'].isin(italics_b_l)]\n",
    "    italics_b_l = page_df[page_df['flags'] == 6]['b_l_tuple'].unique()\n",
    "    page_df = page_df.drop(page_df[page_df['b_l_tuple'].isin(italics_b_l)].index.tolist())\n",
    "    \n",
    "    #updating coordinates to represent target DPI\n",
    "    page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    #get x corner coordinates \n",
    "    x_min = page_df['x0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "\n",
    "    y_max = page_df['y1'].max()\n",
    "\n",
    "    #Remove the extra flore - 18 at page 545\n",
    "    if page_num == index[4]:\n",
    "        page_df = page_df[~((page_df[\"word\"] == 'Flore') & (page_df['y1'] == y_max))]\n",
    "    #invalid words dataframe -- for error checking\n",
    "    pruned_words_df = page_df[~page_df[\"word\"].apply(valid)].reset_index()\n",
    "    #prune out invalid words (based on function valid)\n",
    "    #page_df = page_df[page_df[\"word\"].apply(valid)].reset_index()\n",
    "    \n",
    "    indent_groups = []\n",
    "    blocks = page_df['block_no'].unique()\n",
    "    for b in blocks:\n",
    "        lines = page_df[page_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            #reset word_no values (useful for cases where word that was originally at 0th index was pruned out)\n",
    "            cond = (page_df['line_no'] == l) & (page_df['block_no'] == b)\n",
    "            num_words = len(page_df[cond]['word_no'])\n",
    "            page_df.loc[cond, 'word_no'] = np.arange(num_words).astype(int) #this is slowww\n",
    "            #set column number (0 or 1)\n",
    "            x_0 = page_df[cond]['x0'].min()\n",
    "            #THIS DOESN'T WORK AAAA -- issue was with line no thing\n",
    "            if not np.isnan(x_0):\n",
    "                page_df.loc[cond, 'col_no'] = np.array([int(x_0 > ((x_min + x_max) / 2))]*num_words).astype(int)\n",
    "\n",
    "                #initiate indent groups -- only first word should get an indent_group value \n",
    "                new_group = True\n",
    "                for g_i in range(len(indent_groups)):\n",
    "                    g = indent_groups[g_i]\n",
    "                    g_arr = np.array(g)\n",
    "                    if x_0 <= np.mean(g_arr) + indent_err and x_0 >= np.mean(g_arr) - indent_err:\n",
    "                        g.append(x_0)\n",
    "                        new_group = False\n",
    "                        page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "                if new_group:\n",
    "                    indent_groups.append([x_0])\n",
    "                    g_i = len(indent_groups) - 1\n",
    "                    page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "            \n",
    "    #print(\"indent groups:\", indent_groups)\n",
    "    #return updated page_df, pruned_words_df, indent groups\n",
    "    return page_df.reset_index(), pruned_words_df, indent_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "/opt/homebrew/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_no</th>\n",
       "      <th>type</th>\n",
       "      <th>bbox</th>\n",
       "      <th>lines</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>ext</th>\n",
       "      <th>colorspace</th>\n",
       "      <th>xres</th>\n",
       "      <th>yres</th>\n",
       "      <th>bpc</th>\n",
       "      <th>transform</th>\n",
       "      <th>size</th>\n",
       "      <th>image</th>\n",
       "      <th>_</th>\n",
       "      <th>line_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(146.63999938964844, 82.23709106445312, 281.47...</td>\n",
       "      <td>{'spans': [{'size': 13.100000381469727, 'flags...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(115.44000244140625, 131.1444091796875, 121.17...</td>\n",
       "      <td>{'spans': [{'size': 8.399999618530273, 'flags'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(42.47999954223633, 153.70440673828125, 114.12...</td>\n",
       "      <td>{'spans': [{'size': 8.549408912658691, 'flags'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>(28.559999465942383, 163.30438232421875, 93.46...</td>\n",
       "      <td>{'spans': [{'size': 8.48757553100586, 'flags':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>(42.2400016784668, 172.90438842773438, 151.875...</td>\n",
       "      <td>{'spans': [{'size': 8.399999618530273, 'flags'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>(398.6400146484375, 535.7843627929688, 411.588...</td>\n",
       "      <td>{'spans': [{'size': 8.399999618530273, 'flags'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>{'spans': [{'size': 8.399999618530273, 'flags'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>{'spans': [{'size': 8.399999618530273, 'flags'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>{'spans': [{'size': 8.399999618530273, 'flags'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>{'spans': [{'size': 8.399999618530273, 'flags'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     block_no  type                                               bbox  \\\n",
       "0           0     0  (146.63999938964844, 82.23709106445312, 281.47...   \n",
       "1           1     0  (115.44000244140625, 131.1444091796875, 121.17...   \n",
       "3           3     0  (42.47999954223633, 153.70440673828125, 114.12...   \n",
       "5           5     0  (28.559999465942383, 163.30438232421875, 93.46...   \n",
       "7           7     0  (42.2400016784668, 172.90438842773438, 151.875...   \n",
       "..        ...   ...                                                ...   \n",
       "149       149     0  (398.6400146484375, 535.7843627929688, 411.588...   \n",
       "150       150     0  (403.20001220703125, 565.5443725585938, 411.82...   \n",
       "150       150     0  (403.20001220703125, 565.5443725585938, 411.82...   \n",
       "150       150     0  (403.20001220703125, 565.5443725585938, 411.82...   \n",
       "150       150     0  (403.20001220703125, 565.5443725585938, 411.82...   \n",
       "\n",
       "                                                 lines  width  height  ext  \\\n",
       "0    {'spans': [{'size': 13.100000381469727, 'flags...    NaN     NaN  NaN   \n",
       "1    {'spans': [{'size': 8.399999618530273, 'flags'...    NaN     NaN  NaN   \n",
       "3    {'spans': [{'size': 8.549408912658691, 'flags'...    NaN     NaN  NaN   \n",
       "5    {'spans': [{'size': 8.48757553100586, 'flags':...    NaN     NaN  NaN   \n",
       "7    {'spans': [{'size': 8.399999618530273, 'flags'...    NaN     NaN  NaN   \n",
       "..                                                 ...    ...     ...  ...   \n",
       "149  {'spans': [{'size': 8.399999618530273, 'flags'...    NaN     NaN  NaN   \n",
       "150  {'spans': [{'size': 8.399999618530273, 'flags'...    NaN     NaN  NaN   \n",
       "150  {'spans': [{'size': 8.399999618530273, 'flags'...    NaN     NaN  NaN   \n",
       "150  {'spans': [{'size': 8.399999618530273, 'flags'...    NaN     NaN  NaN   \n",
       "150  {'spans': [{'size': 8.399999618530273, 'flags'...    NaN     NaN  NaN   \n",
       "\n",
       "     colorspace  xres  yres  bpc transform  size image       _  line_no  \n",
       "0           NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        0  \n",
       "1           NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        0  \n",
       "3           NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        0  \n",
       "5           NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        0  \n",
       "7           NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        0  \n",
       "..          ...   ...   ...  ...       ...   ...   ...     ...      ...  \n",
       "149         NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        2  \n",
       "150         NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        0  \n",
       "150         NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        1  \n",
       "150         NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        2  \n",
       "150         NaN   NaN   NaN  NaN       NaN   NaN   NaN  number        3  \n",
       "\n",
       "[193 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_num = index[0] #tqdm(index)\n",
    "words_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "words_df['b_l_tuple'] = tuple(zip(words_df['block_no'], words_df['line_no']))\n",
    "#using get_text to extract 'size', 'flags', 'font'\n",
    "#NOTE: not sure if this is the best way to go about this ...\n",
    "content_blocks_df = pd.DataFrame(pages[page_num].get_text(\"dict\")['blocks'])\n",
    "line_dicts = content_blocks_df[~content_blocks_df['lines'].isnull()].explode('lines', ignore_index=False)\n",
    "line_dicts\n",
    "\n",
    "#block_no is number\n",
    "#type is image vs text\n",
    "#NEW GOAL : for each exploded item --> get sub indexing for that region and use it as the \n",
    "#                                       line_no\n",
    "#                                       word_no\n",
    "\n",
    "line_dicts.set_index(['number',line_dicts.groupby('number').cumcount()]).rename_axis(['block_no','line_no']).tail(10)\n",
    "line_dicts[[\"_\", \"line_no\"]]=['number',line_dicts.groupby('number').cumcount()]\n",
    "line_dicts.rename(columns={\"number\": \"block_no\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>type</th>\n",
       "      <th>bbox</th>\n",
       "      <th>lines</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>ext</th>\n",
       "      <th>colorspace</th>\n",
       "      <th>xres</th>\n",
       "      <th>yres</th>\n",
       "      <th>bpc</th>\n",
       "      <th>transform</th>\n",
       "      <th>size</th>\n",
       "      <th>image</th>\n",
       "      <th>_</th>\n",
       "      <th>line_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(146.63999938964844, 82.23709106445312, 281.47...</td>\n",
       "      <td>spans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(146.63999938964844, 82.23709106445312, 281.47...</td>\n",
       "      <td>wmode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(146.63999938964844, 82.23709106445312, 281.47...</td>\n",
       "      <td>dir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(146.63999938964844, 82.23709106445312, 281.47...</td>\n",
       "      <td>bbox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>(115.44000244140625, 131.1444091796875, 121.17...</td>\n",
       "      <td>spans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>bbox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>spans</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>wmode</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>dir</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>(403.20001220703125, 565.5443725585938, 411.82...</td>\n",
       "      <td>bbox</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>number</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     number  type                                               bbox  lines  \\\n",
       "0         0     0  (146.63999938964844, 82.23709106445312, 281.47...  spans   \n",
       "0         0     0  (146.63999938964844, 82.23709106445312, 281.47...  wmode   \n",
       "0         0     0  (146.63999938964844, 82.23709106445312, 281.47...    dir   \n",
       "0         0     0  (146.63999938964844, 82.23709106445312, 281.47...   bbox   \n",
       "1         1     0  (115.44000244140625, 131.1444091796875, 121.17...  spans   \n",
       "..      ...   ...                                                ...    ...   \n",
       "150     150     0  (403.20001220703125, 565.5443725585938, 411.82...   bbox   \n",
       "150     150     0  (403.20001220703125, 565.5443725585938, 411.82...  spans   \n",
       "150     150     0  (403.20001220703125, 565.5443725585938, 411.82...  wmode   \n",
       "150     150     0  (403.20001220703125, 565.5443725585938, 411.82...    dir   \n",
       "150     150     0  (403.20001220703125, 565.5443725585938, 411.82...   bbox   \n",
       "\n",
       "     width  height  ext  colorspace  xres  yres  bpc transform  size image  \\\n",
       "0      NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "0      NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "0      NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "0      NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "1      NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "..     ...     ...  ...         ...   ...   ...  ...       ...   ...   ...   \n",
       "150    NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "150    NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "150    NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "150    NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "150    NaN     NaN  NaN         NaN   NaN   NaN  NaN       NaN   NaN   NaN   \n",
       "\n",
       "          _  line_no  \n",
       "0    number        0  \n",
       "0    number        0  \n",
       "0    number        0  \n",
       "0    number        0  \n",
       "1    number        0  \n",
       "..      ...      ...  \n",
       "150  number        2  \n",
       "150  number        3  \n",
       "150  number        3  \n",
       "150  number        3  \n",
       "150  number        3  \n",
       "\n",
       "[772 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_dicts\n",
    "content_df = pd.DataFrame(list((pd.DataFrame(list(line_dicts['lines']))['spans'].explode('spans'))))\n",
    "content_df = content_df[content_df['text'] != ' ']\n",
    "content_df['text'] = content_df['text']\n",
    "content_df['text'] = content_df['text'].apply(lambda x : list(x.split()))\n",
    "content_df = content_df.explode('text')\n",
    "split_bbox_df = pd.DataFrame(content_df['bbox'].tolist(), columns=['x0', 'y0', 'x1', 'y1'])\n",
    "pretty_content_df = pd.concat([content_df.reset_index(), split_bbox_df], axis=1)\n",
    "line_dicts.explode('lines')\n",
    "\n",
    "#https://stackoverflow.com/questions/38231591/split-explode-a-column-of-dictionaries-into-separate-columns-with-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding indentations associated with genus, epithet, infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['genus', 'epithet', 'infra', 'author', 'misc.']\n",
    "def n_leftmost_indent(df, n):\n",
    "    \"\"\"return a tuple with at most 3 elements each element itself is a tuple containing indent group, mean, group len\"\"\"\n",
    "    indent_groups = [(g, df[(df['indent_group'] == g) & (df['word_no'] == 0)]['x0'].mean(), len(df[(df['indent_group'] == g) & (df['word_no'] == 0)]['x0'])) for g in df['indent_group'].unique()]\n",
    "    indent_groups.sort(key = lambda x : x[1])\n",
    "    #print(indent_groups[:n])\n",
    "    return indent_groups[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genusEpithetInfra_indent(col_df):\n",
    "    leftmost_3_indents = n_leftmost_indent(col_df, 2) #for vol1 only 2 indentations will be given \n",
    "    min_gap = 0\n",
    "    max_gap = 75 #error is 30 -- less than 50% of max gap (which will be ignored for now)\n",
    "\n",
    "    # possibly not specific enough\n",
    "    # first identifying indent based don distance from one another only\n",
    "    \"\"\"if len(leftmost_3_indents) == 3:\n",
    "        if leftmost_3_indents[0][1] < max_gap:\n",
    "            leftmost_3_indents = leftmost_3_indents[1:]\n",
    "        elif ((leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) > max_gap or \\\n",
    "            (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) < min_gap): #comparing first two (if satisfied last two will be checked in next if block)\n",
    "            leftmost_3_indents = [max(leftmost_3_indents[1:], key = lambda x : x[2])] + [leftmost_3_indents[2]]\n",
    "        elif (leftmost_3_indents[2][1] - leftmost_3_indents[1][1]) > max_gap or \\\n",
    "            (leftmost_3_indents[2][1] - leftmost_3_indents[1][1]) < min_gap: #comparing last two\n",
    "            leftmost_3_indents = [leftmost_3_indents[0]] + [max(leftmost_3_indents[1:], key = lambda x : x[2])]\n",
    "\n",
    "    if len(leftmost_3_indents) == 2:\n",
    "        if leftmost_3_indents[0][1] < max_gap:\n",
    "            leftmost_3_indents = leftmost_3_indents[1]\n",
    "        elif (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) > max_gap or (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) < min_gap:\n",
    "            leftmost_3_indents = [max(leftmost_3_indents, key = lambda x : x[2])]\"\"\"\n",
    "\n",
    "    has_genus, has_epithet, has_infra = False, False, False\n",
    "    genus_indent, epithet_indent, infra_indent = -1, -1, -1\n",
    "    if len(leftmost_3_indents) == 3 and type(leftmost_3_indents) == type([1,2,3]):\n",
    "        has_genus, has_epithet, has_infra = True, True, True\n",
    "        print(\"leftmost 3:\", leftmost_3_indents)\n",
    "        genus_indent, epithet_indent, infra_indent = [el[0] for el in leftmost_3_indents]\n",
    "    elif len(leftmost_3_indents) == 2:\n",
    "        if col_df[col_df['indent_group'] == leftmost_3_indents[1][0]]['word'].apply(is_infra).any():\n",
    "            has_genus, has_epithet, has_infra = False, True, True\n",
    "            epithet_indent, infra_indent = [el[0] for el in leftmost_3_indents]\n",
    "        else:\n",
    "            has_genus, has_epithet, has_infra = True, True, False\n",
    "            genus_indent, epithet_indent = [el[0] for el in leftmost_3_indents]\n",
    "    elif len(leftmost_3_indents) == 1 or type(leftmost_3_indents) == type((1,2,3)): \n",
    "        if type(leftmost_3_indents) == type((1,2,3)):\n",
    "            leftmost_3_indents = [leftmost_3_indents]\n",
    "        has_genus, has_epithet, has_infra = False, True, False\n",
    "        epithet_indent = leftmost_3_indents[0][0]\n",
    "\n",
    "    return genus_indent, epithet_indent, infra_indent, leftmost_3_indents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing column dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_col(col_df, genus, epithet, draw_genus, draw_epithet, draw_infra = np.NaN):\n",
    "    genus_indent, epithet_indent, infra_indent, indent_3_left = get_genusEpithetInfra_indent(col_df)\n",
    "    #print(genus_indent, epithet_indent, infra_indent, indent_3_left)\n",
    "    \n",
    "    blocks = col_df['block_no'].unique()\n",
    "    start_word_cond = -1 \n",
    "    author = ''\n",
    "    #draw_infra = np.NaN\n",
    "    \n",
    "    col_df = col_df.copy()\n",
    "    for index, row in col_df.iterrows():\n",
    "        b, l, w = row['block_no'], row['line_no'], row['word_no']\n",
    "        word, indent_group = row['word'], row['indent_group']\n",
    "        row_cond = (col_df['line_no'] == l) & (col_df['block_no'] == b) & (col_df['word_no'] == w) \n",
    "        process_hybrid = False\n",
    "        process_infra = False\n",
    "        if w == 0: \n",
    "            start_word_cond = row_cond\n",
    "            if indent_group == genus_indent and not ''.join(e for e in word if e.isalpha()).isupper():\n",
    "                genus = word\n",
    "                draw_genus = genus\n",
    "                epithet = ''\n",
    "                draw_epithet = ''\n",
    "                author = ''\n",
    "                misc = ''\n",
    "                infra = ''\n",
    "                col_df.loc[start_word_cond, 'genus'] = genus\n",
    "                col_df.loc[start_word_cond, 'taxon rank'] = 'genus'\n",
    "                if not is_genus(word):\n",
    "                    col_df.loc[row_cond, 'error_check'] = True\n",
    "                col_df.loc[row_cond, 'draw_genus'] = draw_genus\n",
    "                col_df.loc[row_cond, 'author'] = ''\n",
    "\n",
    "            elif indent_group == epithet_indent and not ''.join(e for e in word if e.isalpha()).isupper():\n",
    "                epithet = word\n",
    "                author = ''\n",
    "                col_df.loc[row_cond, 'genus'] = genus\n",
    "                col_df.loc[row_cond, 'epithet'] = epithet\n",
    "                col_df.loc[row_cond, 'taxon rank'] = 'species'\n",
    "                if not is_epithet(word):\n",
    "                    col_df.loc[row_cond, 'error_check'] = True\n",
    "                draw_epithet = str(genus) + '_' + str(epithet) +'_' + str(b) + '_' + str(l)\n",
    "                col_df.loc[row_cond, 'draw_genus'] = draw_genus\n",
    "                col_df.loc[row_cond, 'draw_epithet'] = draw_epithet\n",
    "                col_df.loc[row_cond, 'author'] = ''\n",
    "        \n",
    "        else:\n",
    "            #print(genus, epithet)\n",
    "            if w == 1 and epithet == '': \n",
    "                epithet = word\n",
    "                misc = ''\n",
    "                infra = ''\n",
    "                author = ''\n",
    "                start_word_cond = row_cond\n",
    "                col_df.loc[row_cond, 'genus'] = genus\n",
    "                col_df.loc[row_cond, 'epithet'] = epithet\n",
    "                col_df.loc[row_cond, 'taxon rank'] = 'species'\n",
    "                if not is_epithet(word):\n",
    "                    col_df.loc[row_cond, 'error_check'] = True\n",
    "                draw_epithet = str(genus) + '_' + str(epithet) +'_' + str(b) + '_' + str(l)\n",
    "                col_df.loc[row_cond, 'draw_genus'] = draw_genus\n",
    "                col_df.loc[row_cond, 'draw_epithet'] = draw_epithet\n",
    "                col_df.loc[row_cond, 'author'] = ''\n",
    "            elif (type(genus) == type(\"STR\") and genus != '') or (type(epithet) == type(\"STR\") and epithet != ''):\n",
    "                #print(col_df.loc[start_word_cond, 'author'])\n",
    "                \"\"\"if np.isnan(col_df.loc[start_word_cond, 'author'].item()):\n",
    "                    author == ''\n",
    "                    col_df.loc[start_word_cond, 'author'] = ''\"\"\"\n",
    "                curr_author_part = word +  ' '\n",
    "                col_df.loc[start_word_cond, 'author'] += curr_author_part\n",
    "                col_df.loc[row_cond, 'draw_author'] = 'author_'+str(b)+'_'+str(l)\n",
    "                col_df.loc[row_cond, 'draw_genus'] = draw_genus\n",
    "            #col_df.loc[word_cond, 'draw_genus'] = draw_genus\n",
    "            #if epithet:\n",
    "            #    col_df.loc[word_cond, 'draw_epithet'] = draw_epithet\n",
    "            #if infra: \n",
    "            #    col_df.loc[word_cond, 'draw_infra'] = draw_infra\"\"\"\n",
    "\n",
    "    #Last author\n",
    "    \"\"\"if author != '':\n",
    "        col_df.loc[start_word_cond, 'author'] = author\"\"\"\n",
    "                    \n",
    "\n",
    "    return col_df, genus, epithet, draw_genus, draw_epithet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:01<00:00, 19.17it/s]\n",
      "100%|██████████| 23/23 [00:04<00:00,  5.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#preprocessing\n",
    "genus = np.NaN\n",
    "df_dict = {}\n",
    "pruned_dict = {}\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    page_df, pruned_df, indent_group = preprocessing(page_num)\n",
    "    df_dict[page_num] = page_df\n",
    "    pruned_dict[page_num] = pruned_df\n",
    "\n",
    "genus = np.NaN\n",
    "epithet = np.NaN\n",
    "draw_genus = np.NaN\n",
    "draw_epithet = np.NaN\n",
    "result_ims_valid_words = []\n",
    "df_list = []\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    #page_num = index[-1]\n",
    "    #process the pre-processed dfs\n",
    "    page_df = df_dict[page_num]\n",
    "    \n",
    "    #for drawing\n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    plot_valid_words(page_df, draw, color = '#660044', w = 2)\n",
    "    result_ims_valid_words.append(image)\n",
    "    \n",
    "    #break \n",
    "#result_ims_valid_words[0].save(OUTPUT_PATH + \"preprocessed/\" + 'valid_words' + TAIL_STR + '.pdf',save_all=True, append_images=result_ims[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Results + SAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up files and directories for saving the results\n",
    "SCRIPT_NAME = \"vol1_index_synonyms.ipynb\"\n",
    "SCRIPT_OUTPUT_PATH = \"../output/index/\" + SCRIPT_NAME + \"/\"\n",
    "DATE_STR = datetime.now().strftime(\"%Y_%m_%d\") \n",
    "TIME_STR = datetime.now().strftime(\"%H%M\")\n",
    "QUICK_FIX = False\n",
    "TAIL_STR = ''\n",
    "\n",
    "if QUICK_FIX:\n",
    "    OUTPUT_PATH = SCRIPT_OUTPUT_PATH + DATE_STR + \"/QuickFix/\" \n",
    "    #TAIL_STR = '_' + DATE_STR + '_' + TIME_STR\n",
    "else:\n",
    "    OUTPUT_PATH = SCRIPT_OUTPUT_PATH + DATE_STR + \"/\" + TIME_STR + \"/\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTPUT_PATH + \"preprocessed/\")\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTPUT_PATH + 'raw/')\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed_df = pd.concat([df_dict[k] for k in df_dict], axis = 0)\n",
    "result_ims_valid_words[0].save(OUTPUT_PATH + \"preprocessed/\" + 'valid_words' + TAIL_STR + '.pdf',save_all=True, append_images=result_ims_valid_words[1:])\n",
    "pre_processed_df.to_html(OUTPUT_PATH + \"preprocessed/\" + 'vol1_preprocessed_index' + TAIL_STR + '.html')\n",
    "pre_processed_df.to_csv(OUTPUT_PATH + \"preprocessed/\" + 'vol1_preprocessed_index' + TAIL_STR + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:05<00:00,  3.86it/s]\n"
     ]
    }
   ],
   "source": [
    "genus = np.NaN\n",
    "epithet = np.NaN\n",
    "draw_genus = np.NaN\n",
    "draw_epithet = np.NaN\n",
    "result_ims = []\n",
    "df_list = []\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    #if page_num == index[-2]:\n",
    "    #    break\n",
    "    #page_num = index[-1]\n",
    "    #process the pre-processed dfs\n",
    "    page_df = df_dict[page_num]\n",
    "    \n",
    "    #for drawing\n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    #processing each column\n",
    "    for c in page_df['col_no'].unique():\n",
    "        col_df = page_df[page_df['col_no'] == c]\n",
    "        col_df, genus, epithet, draw_genus, draw_epithet = process_col(col_df, genus, epithet, draw_genus, draw_epithet)\n",
    "        df_list.append(col_df)\n",
    "\n",
    "        #drawing boxes in each column\n",
    "        plot_genus_blocks(col_df, draw)\n",
    "        plot_epithet_blocks(col_df, draw)\n",
    "        plot_author_blocks(col_df, draw)\n",
    "        plot_infra_blocks(col_df, draw)\n",
    "\n",
    "    result_ims.append(image)\n",
    "\n",
    "#TIME_STR = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%p\")\n",
    "result_ims[0].save(OUTPUT_PATH + 'vol1_index_ROI.pdf',save_all=True, append_images=result_ims[1:])\n",
    "\n",
    "pre_processed_df = pd.concat([df_dict[k] for k in df_dict], axis = 0)\n",
    "result_ims_valid_words[0].save(OUTPUT_PATH + \"preprocessed/\" + 'valid_words' + TAIL_STR + '.pdf',save_all=True, append_images=result_ims_valid_words[1:])\n",
    "pre_processed_df.to_html(OUTPUT_PATH + \"preprocessed/\" + 'vol1_preprocessed_index' + TAIL_STR + '.html')\n",
    "pre_processed_df.to_csv(OUTPUT_PATH + \"preprocessed/\" + 'vol1_preprocessed_index' + TAIL_STR + '.csv')\n",
    "\n",
    "df = pd.concat(df_list, axis = 0)\n",
    "df.to_html(OUTPUT_PATH + 'raw/' + 'vol1_index' + TAIL_STR + '.html')\n",
    "df.to_csv(OUTPUT_PATH + 'raw/' + 'vol1_index' + TAIL_STR + '.csv', index = False)\n",
    "\n",
    "pruned = df[(~df['genus'].isnull())]\n",
    "pruned = pruned[[\"page_num\", \"genus\", \"epithet\", \"infra\" ,\"author\", \"taxon rank\"]]\n",
    "pruned.to_csv(OUTPUT_PATH + 'vol1_index_pruned' + TAIL_STR + '.csv', index = False)\n",
    "pruned.to_html(OUTPUT_PATH + 'vol1_index_pruned' + TAIL_STR + '.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
