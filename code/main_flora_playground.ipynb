{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import fitz\n",
    "import re\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import operator\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_blocks(page_df, draw, color = '#660044', w = 2):\n",
    "    blocks = page_df['block_no'].unique()\n",
    "    \"\"\"for b in blocks:\n",
    "        lines = page_df[page_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            cond = (page_df['line_no'] == l) & (page_df['block_no'] == b)\n",
    "            words = page_df[cond]['word_no'].unique()\n",
    "            page_df = page_df.copy()\n",
    "            for w in words:\n",
    "                x0 = page_df[(cond) & (page_df['word_no'] == w)]['x0'].item()\n",
    "                y0 = page_df[(cond) & (page_df['word_no'] == w)]['y0'].item()\n",
    "                x1 = page_df[(cond) & (page_df['word_no'] == w)]['x1'].item()\n",
    "                y1 = page_df[(cond) & (page_df['word_no'] == w)]['y1'].item()\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "    \"\"\"\n",
    "    for b in blocks:\n",
    "        sub_df = page_df[page_df['block_no'] == b]\n",
    "        x0, y0, x1, y1 = sub_df['x0'].min(), sub_df['y0'].min(), sub_df['x1'].max(), sub_df['y1'].max() \n",
    "        draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "    #for index, row in page_df.iterrows():\n",
    "    #    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1'] \n",
    "    #    draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(color), width = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf\"\n",
    "pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf\"\n",
    "#index = range(616, 639)\n",
    "doc = fitz.open(pdf_dir)\n",
    "pages = [doc[i] for i in range(doc.page_count)]\n",
    "#index = list(range(555, 583))\n",
    "\n",
    "pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf\"\n",
    "#index = range(616, 639)\n",
    "\n",
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)\n",
    "\n",
    "indent_groups = []\n",
    "indent_err = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up files and directories for saving the results\n",
    "SCRIPT_NAME = \"main_flora_playground\"\n",
    "SCRIPT_OUTPUT_PATH = \"../output/main_text/\" + SCRIPT_NAME + \"/\"\n",
    "DATE_STR = datetime.now().strftime(\"%Y_%m_%d\") \n",
    "TIME_STR = datetime.now().strftime(\"%H%M\")\n",
    "QUICK_FIX = False\n",
    "TAIL_STR = ''\n",
    "\n",
    "if QUICK_FIX:\n",
    "    OUTPUT_PATH = SCRIPT_OUTPUT_PATH + DATE_STR + \"/QuickFix/\" \n",
    "    #TAIL_STR = '_' + DATE_STR + '_' + TIME_STR\n",
    "else:\n",
    "    OUTPUT_PATH = SCRIPT_OUTPUT_PATH + DATE_STR + \"/\" + TIME_STR + \"/\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "except FileExistsError:\n",
    "    # directory already exists\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(word):\n",
    "    \"\"\"\n",
    "    valid words are words that are:\n",
    "    - at least 2 characters\n",
    "        - unless it's x (symbol for hybrid)\n",
    "    \"\"\"\n",
    "    return (not bool(re.search(r\"[0-9]+[,.]?\", word))) and \\\n",
    "            (word != 'NOUVELLE' and word != 'FLORE') and \\\n",
    "            (len(word) > 1 or \\\n",
    "                word == 'x' or word == 'X' or word == '×' or word == r'\\u00D7') and \\\n",
    "            ''.join(e for e in word if e.isalpha()).isalpha()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(page_num, indent_err = 30):\n",
    "    \n",
    "    #initiate dataframe\n",
    "    page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    \n",
    "    #add page number to dataframe\n",
    "    page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    #initiate all columns that will be added\n",
    "    page_df['genus'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_genus'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['epithet'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_epithet'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['author'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_author'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['infra'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_infra'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['taxon rank'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['error_check'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    #updating coordinates to represent target DPI\n",
    "    page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    #get x corner coordinates \n",
    "    x_min = page_df['x0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "\n",
    "    y_max = page_df['y1'].max()\n",
    "\n",
    "    #Remove the extra flore - 18 at page 545\n",
    "    #if page_num == index[4]:\n",
    "    #    page_df = page_df[~((page_df[\"word\"] == 'Flore') & (page_df['y1'] == y_max))]\n",
    "    #invalid words dataframe -- for error checking\n",
    "    #pruned_words_df = page_df[~page_df[\"word\"].apply(valid)].reset_index()\n",
    "    #prune out invalid words (based on function valid)\n",
    "    all_df = page_df.copy()\n",
    "    page_df = page_df[page_df[\"word\"].apply(valid)].reset_index()\n",
    "    \n",
    "    indent_groups = []\n",
    "    blocks = page_df['block_no'].unique()\n",
    "    for b in blocks:\n",
    "        lines = page_df[page_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            #reset word_no values (useful for cases where word that was originally at 0th index was pruned out)\n",
    "            cond = (page_df['line_no'] == l) & (page_df['block_no'] == b)\n",
    "            num_words = len(page_df[cond]['word_no'])\n",
    "            page_df.loc[cond, 'word_no'] = np.arange(num_words).astype(int) #this is slowww\n",
    "            #set column number (0 or 1)\n",
    "            x_0 = page_df[cond]['x0'].min()\n",
    "            #THIS DOESN'T WORK AAAA -- issue was with line no thing\n",
    "            if not np.isnan(x_0):\n",
    "                page_df.loc[cond, 'col_no'] = np.array([int(x_0 > ((x_min + x_max) / 2))]*num_words).astype(int)\n",
    "\n",
    "                #initiate indent groups -- only first word should get an indent_group value \n",
    "                new_group = True\n",
    "                for g_i in range(len(indent_groups)):\n",
    "                    g = indent_groups[g_i]\n",
    "                    g_arr = np.array(g)\n",
    "                    if x_0 <= np.mean(g_arr) + indent_err and x_0 >= np.mean(g_arr) - indent_err:\n",
    "                        g.append(x_0)\n",
    "                        new_group = False\n",
    "                        page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "                if new_group:\n",
    "                    indent_groups.append([x_0])\n",
    "                    g_i = len(indent_groups) - 1\n",
    "                    page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "\n",
    "    #print(\"indent groups:\", indent_groups)\n",
    "    #return updated page_df, pruned_words_df, indent groups\n",
    "    return all_df, page_df.reset_index()\n",
    "\n",
    "#https://stackoverflow.com/questions/53468558/adding-image-to-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [01:10<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "result_ims = []\n",
    "df_dict = {}\n",
    "\n",
    "for page_num in tqdm(range(2*doc.page_count//4, 3*doc.page_count//4)):\n",
    "    all_df, page_df = preprocessing(page_num, indent_err = 30)\n",
    "    df_dict[page_num] = {\"all\" : all_df, \"pruned\" : page_df}\n",
    "    #pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    #page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    plot_blocks(page_df, draw, color = '#660044', w = 2)\n",
    "    result_ims.append(image)\n",
    "\n",
    "result_ims[0].save(OUTPUT_PATH + 'block_regions_third_quarter.pdf',save_all=True, append_images=result_ims[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#types = ['genus', 'epithet', 'infra', 'author', 'misc.']\n",
    "def n_leftmost_indent(df, n):\n",
    "    \"\"\"return a tuple with at most 3 elements each element itself is a tuple containing indent group, mean, group len\"\"\"\n",
    "    indent_groups = [(g, df[(df['indent_group'] == g) & (df['word_no'] == 0)]['x0'].mean(), len(df[(df['indent_group'] == g) & (df['word_no'] == 0)]['x0'])) for g in df['indent_group'].unique()]\n",
    "    indent_groups.sort(key = lambda x : x[1])\n",
    "    #print(indent_groups[:n])\n",
    "    return indent_groups[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_paragraph_indent(all_df, page_df):\n",
    "    leftmost_3_indents = n_leftmost_indent(page_df, 2) #for vol1 only 2 indentations will be given \n",
    "    min_gap = 0\n",
    "    max_gap = 75 #error is 30 -- less than 50% of max gap (which will be ignored for now)\n",
    "\n",
    "    cont_indent, start_indent = [el[0] for el in leftmost_3_indents]\n",
    "    \n",
    "    blocks = page_df['block_no'].unique()\n",
    "    for b in blocks:\n",
    "        block_cond = all_df['block_no'] == b\n",
    "        if page_df['indent_group'].min() == cont_indent: #mostly .min() is place holder... makes sense though \n",
    "            all_df.loc[block_cond, 'paragraph_state'] = \"cont\"\n",
    "        if page_df['indent_group'].min() == start_indent:\n",
    "            all_df.loc[block_cond, 'paragraph_state'] = \"start\"\n",
    "        else:\n",
    "            all_df.loc[block_cond, 'paragraph_state'] = \"misc\"\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_blocks_by_cond(page_df, draw, w = 2):\n",
    "    blocks = page_df['block_no'].unique()\n",
    "    \"\"\"for b in blocks:\n",
    "        lines = page_df[page_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            cond = (page_df['line_no'] == l) & (page_df['block_no'] == b)\n",
    "            words = page_df[cond]['word_no'].unique()\n",
    "            page_df = page_df.copy()\n",
    "            for w in words:\n",
    "                x0 = page_df[(cond) & (page_df['word_no'] == w)]['x0'].item()\n",
    "                y0 = page_df[(cond) & (page_df['word_no'] == w)]['y0'].item()\n",
    "                x1 = page_df[(cond) & (page_df['word_no'] == w)]['x1'].item()\n",
    "                y1 = page_df[(cond) & (page_df['word_no'] == w)]['y1'].item()\n",
    "                draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "    \"\"\"\n",
    "    for b in blocks:\n",
    "        sub_df = page_df[page_df['block_no'] == b]\n",
    "        x0, y0, x1, y1 = sub_df['x0'].min(), sub_df['y0'].min(), sub_df['x1'].max(), sub_df['y1'].max() \n",
    "        if sub_df['paragraph_state'].any() == \"start\":\n",
    "            color = '#e3a79f'\n",
    "        elif sub_df['paragraph_state'].any() == \"cont\": \n",
    "            color = '#9fe3e1'\n",
    "        elif sub_df['paragraph_state'].any() == \"misc\": \n",
    "            color = '#eaebb5'\n",
    "        else: \n",
    "            color = '#ffffff'\n",
    "        draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "    #for index, row in page_df.iterrows():\n",
    "    #    x0, y0, x1, y1 = row['x0'], row['y0'], row['x1'], row['y1'] \n",
    "    #    draw.rectangle((x0, y0, x1, y1), fill=None, outline=ImageColor.getrgb(color), width = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:52<00:00,  3.03it/s]\n"
     ]
    }
   ],
   "source": [
    "paragraph_result_ims = []\n",
    "for page_num in tqdm(range(2*doc.page_count//4, 3*doc.page_count//4)):\n",
    "    all_df, page_df = df_dict[page_num][\"all\"], df_dict[page_num][\"pruned\"]\n",
    "    all_df = set_paragraph_indent(all_df, page_df)\n",
    "\n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    plot_blocks_by_cond(all_df, draw, w = 2)\n",
    "    paragraph_result_ims.append(image)\n",
    "\n",
    "paragraph_result_ims[0].save(OUTPUT_PATH + 'paragraph_states_third_quarter.pdf',save_all=True, append_images=paragraph_result_ims[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ims[0].save(OUTPUT_PATH + 'paragraph_states_third_quarter.pdf',save_all=True, append_images=result_ims[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_df['paragraph_state'] == 'misc').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}